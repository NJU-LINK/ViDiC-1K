import requests
import os
import json
import time
import traceback
import re
import threading
from threading import Lock, Thread, Semaphore
from queue import Queue
from datetime import datetime
import sys
import argparse

# Set standard output to UTF-8 encoding
sys.stdout.reconfigure(encoding='utf-8')

# ==================== Configuration ====================
MODEL_NAME = "gpt-5-mini"

# ==================== Global Locks ====================
file_lock = Lock()
console_lock = Lock()


# ==================== Utility Functions ====================
def safe_print(msg):
    """Thread-safe print"""
    with console_lock:
        timestamp = datetime.now().strftime("%H:%M:%S")
        print(f"[{timestamp}] {msg}")


def safe_post_json(url, headers, payload, max_retries=3, timeout=120):
    """POST request with retry mechanism"""
    for attempt in range(1, max_retries + 1):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=timeout)
            if response.status_code == 200:
                return response
            elif response.status_code == 429:
                wait_time = min(2 ** attempt * 5, 60)
                safe_print(f"‚ö†Ô∏è  Rate limited, waiting {wait_time} seconds")
                time.sleep(wait_time)
            else:
                safe_print(f"‚ùå Request failed ({response.status_code}): {response.text[:100]}")
        except requests.exceptions.Timeout:
            safe_print(f"‚ö†Ô∏è  Timeout on attempt {attempt}")
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  Exception on attempt {attempt}: {e}")
        
        if attempt < max_retries:
            time.sleep(min(2 ** attempt, 10))
    
    raise RuntimeError("Request failed after maximum retries")


def parse_judge_response(raw_text):
    """Parse API response for judgment result"""
    if raw_text is None:
        return {"answer": "error", "explanation": "Empty response"}
    
    if isinstance(raw_text, dict):
        return {
            "answer": raw_text.get("answer", "error"),
            "explanation": raw_text.get("explanation", "")
        }
    
    if not isinstance(raw_text, str):
        raw_text = str(raw_text)
    
    # Try to extract JSON code block
    match = re.search(r"```json\s*(.*?)\s*```", raw_text, re.DOTALL)
    if match:
        try:
            parsed = json.loads(match.group(1))
            return {
                "answer": parsed.get("answer", "error"),
                "explanation": parsed.get("explanation", "")
            }
        except:
            pass
    
    # Try direct JSON parsing
    try:
        parsed = json.loads(raw_text)
        return {
            "answer": parsed.get("answer", "error"),
            "explanation": parsed.get("explanation", "")
        }
    except:
        pass
    
    # Regex extraction
    answer_match = re.search(r"answer\s*[:Ôºö]\s*(yes|no|unsure)", raw_text, re.I)
    reason_match = re.search(r"(explanation|because|reason)[:Ôºö]?\s*(.*)", raw_text, re.I | re.DOTALL)
    
    return {
        "answer": answer_match.group(1).lower() if answer_match else "error",
        "explanation": reason_match.group(2).strip() if reason_match else raw_text.strip()
    }


# ==================== File Operations ====================
def save_result(data, output_path):
    """Thread-safe save (caller must have lock)"""
    abs_path = os.path.abspath(output_path)
    temp_path = f"{output_path}.tmp"
    
    try:
        # Ensure directory exists
        dir_path = os.path.dirname(abs_path)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)
        
        # Write to temporary file
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        temp_size = os.path.getsize(temp_path)
        safe_print(f"üíæ Temporary file: {temp_size} bytes")
        
        # Atomic replace
        if os.path.exists(output_path):
            os.remove(output_path)
        os.rename(temp_path, output_path)
        
        # Verify
        if os.path.exists(output_path):
            final_size = os.path.getsize(output_path)
            safe_print(f"‚úÖ Save successful: {final_size} bytes")
            return True
        else:
            safe_print(f"‚ùå Save failed: file does not exist")
            return False
            
    except Exception as e:
        safe_print(f"‚ùå Save exception: {e}")
        traceback.print_exc()
        return False


def load_progress(progress_file):
    """Load checkpoint progress"""
    if os.path.exists(progress_file):
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                safe_print(f"üìÇ Loaded progress: {len(data)} objects completed")
                return set(data)
        except Exception as e:
            safe_print(f"‚ö†Ô∏è  Progress file corrupted: {e}")
    return set()


def save_progress(completed_objects, progress_file):
    """Save checkpoint progress"""
    try:
        dir_path = os.path.dirname(progress_file)
        if dir_path:
            os.makedirs(dir_path, exist_ok=True)
        
        temp_path = f"{progress_file}.tmp"
        with open(temp_path, 'w', encoding='utf-8') as f:
            json.dump(sorted(list(completed_objects)), f)
        
        if os.path.exists(progress_file):
            os.remove(progress_file)
        os.rename(temp_path, progress_file)
        
    except Exception as e:
        safe_print(f"‚ö†Ô∏è  Progress save failed: {e}")


def load_clean_data(structured_path):
    """Load raw data and clean old results"""
    with open(structured_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    cleaned_count = 0
    for item in data:
        for section in ["Similarities", "Differences"]:
            for question in item["structured_analysis"].get(section, []):
                if question.pop("answer", None) is not None:
                    cleaned_count += 1
                question.pop("explanation", None)
    
    if cleaned_count > 0:
        safe_print(f"üßπ Cleaned {cleaned_count} old results")
    
    return data


def restore_from_output(checklist_data, output_path, completed_objects):
    """Restore completed results from output file"""
    if not os.path.exists(output_path) or not completed_objects:
        return
    
    try:
        with open(output_path, 'r', encoding='utf-8') as f:
            saved_data = json.load(f)
        
        restored_count = 0
        for item_index in completed_objects:
            if item_index < len(saved_data):
                checklist_data[item_index] = saved_data[item_index]
                for section in ["Similarities", "Differences"]:
                    for q in saved_data[item_index]["structured_analysis"].get(section, []):
                        if "answer" in q:
                            restored_count += 1
        
        safe_print(f"‚ôªÔ∏è  Restored {len(completed_objects)} objects, {restored_count} questions")
        
    except Exception as e:
        safe_print(f"‚ö†Ô∏è  Restoration failed: {e}")


def load_prompt_template(prompt_path):
    """Load prompt template from file"""
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read().strip()
    except Exception as e:
        safe_print(f"‚ùå Failed to load prompt template: {e}")
        raise


# ==================== Core Processing Logic ====================
def process_question(question_text, model_description, section, headers, prompt_template, api_url, model_name):
    """Process a single question"""
    full_prompt = prompt_template.format(
        description=model_description,
        question=question_text
    )
    
    payload = {
        "model": model_name,
        "messages": [
            {
                "role": "system",
                "content": f"You are a rigorous video analysis assistant. This is a {section} problem."
            },
            {
                "role": "user",
                "content": full_prompt
            }
        ]
    }
    
    try:
        response = safe_post_json(api_url, headers, payload)
        result = response.json()
        message_text = result["choices"][0]["message"]["content"]
        parsed = parse_judge_response(message_text)
        
        return {
            "answer": parsed.get("answer", "error"),
            "explanation": parsed.get("explanation", message_text.strip())
        }
    except Exception as e:
        return {
            "answer": "error",
            "explanation": f"Processing failed: {str(e)}"
        }


def process_object(item_index, item, response_dict, headers, prompt_template, semaphore, api_url, model_name):
    """Process all questions for one object"""
    key = (item["video1_path"], item["video2_path"])
    
    if key not in response_dict:
        safe_print(f"‚ö†Ô∏è  [Object {item_index}] No matching description")
        model_description = ""
        has_description = False
    else:
        model_description = response_dict[key]
        has_description = True
    
    video_pair = f"{os.path.basename(item['video1_path'])} vs {os.path.basename(item['video2_path'])}"
    total_questions = sum(len(item["structured_analysis"].get(s, [])) for s in ["Similarities", "Differences"])
    
    safe_print(f"üîπ [Object {item_index}] Starting: {video_pair} ({total_questions} questions)")
    
    completed_questions = 0
    
    for section in ["Similarities", "Differences"]:
        for question in item["structured_analysis"].get(section, []):
            question_text = question.get("question", "")
            
            if not has_description:
                result = {
                    "answer": "error",
                    "explanation": "No model description"
                }
            else:
                with semaphore:
                    result = process_question(
                        question_text,
                        model_description,
                        section,
                        headers,
                        prompt_template,
                        api_url,
                        model_name
                    )
            
            question.update(result)
            completed_questions += 1
    
    safe_print(f"‚úÖ [Object {item_index}] Completed: {video_pair} ({completed_questions}/{total_questions})")
    return True


def worker_thread(task_queue, checklist_data, response_dict, headers, prompt_template,
                  output_path, progress_file, completed_objects, semaphore, api_url, model_name):
    """Worker thread"""
    thread_name = threading.current_thread().name
    
    while True:
        try:
            item_index = task_queue.get(timeout=1)
        except:
            continue
        
        if item_index is None:
            safe_print(f"üõë [{thread_name}] Received stop signal")
            task_queue.task_done()
            break
        
        try:
            item = checklist_data[item_index]
            
            # Process object
            process_object(item_index, item, response_dict, headers, prompt_template, semaphore, api_url, model_name)
            
            # Save immediately
            safe_print(f"üíæ [{thread_name}] [Object {item_index}] Preparing to save")
            
            with file_lock:
                completed_objects.add(item_index)
                
                if save_result(checklist_data, output_path):
                    save_progress(completed_objects, progress_file)
                    safe_print(f"üìä Progress: {len(completed_objects)}/{len(checklist_data)}")
                else:
                    safe_print(f"‚ùå [{thread_name}] [Object {item_index}] Save failed")
                    completed_objects.discard(item_index)
            
        except Exception as e:
            safe_print(f"‚ùå [{thread_name}] [Object {item_index}] Exception: {e}")
            traceback.print_exc()
            
            # Mark as error and save
            with file_lock:
                try:
                    for section in ["Similarities", "Differences"]:
                        for question in item["structured_analysis"].get(section, []):
                            question.update({
                                "answer": "error",
                                "explanation": f"Exception: {str(e)}"
                            })
                    completed_objects.add(item_index)
                    save_result(checklist_data, output_path)
                    save_progress(completed_objects, progress_file)
                except Exception as save_err:
                    safe_print(f"‚ùå [{thread_name}] Error state save failed: {save_err}")
        
        finally:
            task_queue.task_done()
    
    safe_print(f"üëã [{thread_name}] Thread exiting")


# ==================== Main Function ====================
def judge_checklist_multithreaded(
    prompt_template,
    structured_path,
    response_path,
    output_path,
    api_url,
    api_key,
    model_name=MODEL_NAME,
    num_threads=4,
    max_concurrent_requests=10
):
    """Multi-threaded judgment main function"""
    
    safe_print("=" * 60)
    safe_print("üöÄ Starting multi-threaded judgment task")
    safe_print("=" * 60)
    
    progress_file = f"{output_path}.progress"
    
    # Ensure output directory exists
    output_dir = os.path.dirname(output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
        safe_print(f"üìÅ Output directory: {os.path.abspath(output_dir)}")
    
    # Pre-create empty output file
    if not os.path.exists(output_path):
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump([], f)
        safe_print(f"üìÑ Created empty output file")
    
    # Load data
    safe_print(f"üìÇ Loading raw data: {structured_path}")
    checklist_data = load_clean_data(structured_path)
    total_objects = len(checklist_data)
    safe_print(f"‚úÖ Loaded {total_objects} objects")
    
    # Load progress
    completed_objects = load_progress(progress_file)
    
    # Restore data
    if completed_objects:
        restore_from_output(checklist_data, output_path, completed_objects)
    
    # Load model descriptions
    safe_print(f"üìÇ Loading model descriptions: {response_path}")
    with open(response_path, 'r', encoding='utf-8') as f:
        model_data = json.load(f)
    
    response_dict = {}
    for item in model_data:
        key = (item["video1_path"], item["video2_path"])
        response_text = item.get("response", "")
        if isinstance(response_text, dict):
            response_text = json.dumps(response_text, ensure_ascii=False)
        response_dict[key] = str(response_text)
    
    safe_print(f"‚úÖ Loaded {len(response_dict)} descriptions")
    
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }
    
    # Create task queue
    task_queue = Queue()
    pending_objects = []
    
    for item_index in range(total_objects):
        if item_index not in completed_objects:
            task_queue.put(item_index)
            pending_objects.append(item_index)
    
    safe_print("=" * 60)
    safe_print(f"üìä Total objects: {total_objects}")
    safe_print(f"üìä Completed: {len(completed_objects)}")
    safe_print(f"üìä Pending: {len(pending_objects)}")
    safe_print("=" * 60)
    
    if not pending_objects:
        safe_print("‚úÖ All objects completed")
        return
    
    # Start threads
    safe_print(f"üöÄ Starting {num_threads} threads")
    safe_print(f"‚ö° Max concurrent: {max_concurrent_requests}")
    
    semaphore = Semaphore(max_concurrent_requests)
    threads = []
    start_time = time.time()
    
    for i in range(num_threads):
        t = Thread(
            target=worker_thread,
            args=(task_queue, checklist_data, response_dict, headers, prompt_template,
                  output_path, progress_file, completed_objects, semaphore, api_url, model_name),
            name=f"Worker-{i+1}"
        )
        t.daemon = False
        t.start()
        threads.append(t)
    
    safe_print(f"‚úÖ {num_threads} threads started")
    
    # Wait for tasks to complete
    safe_print("‚è≥ Waiting for tasks to complete...")
    task_queue.join()
    safe_print("‚úÖ All tasks completed")
    
    # Send stop signals
    safe_print("üõë Sending stop signals...")
    for _ in range(num_threads):
        task_queue.put(None)
    
    # Wait for threads to exit
    for t in threads:
        t.join(timeout=10)
        if t.is_alive():
            safe_print(f"‚ö†Ô∏è  {t.name} did not exit normally")
    
    # Final save
    safe_print("üíæ Performing final save...")
    with file_lock:
        save_result(checklist_data, output_path)
    
    elapsed_time = time.time() - start_time
    
    safe_print("=" * 60)
    safe_print("üéâ Task completed")
    safe_print(f"   Processed objects: {len(completed_objects)}")
    safe_print(f"   Total time: {elapsed_time:.1f} seconds")
    safe_print(f"   Output file: {os.path.abspath(output_path)}")
    
    # Verify file
    if os.path.exists(output_path):
        file_size = os.path.getsize(output_path) / 1024
        safe_print(f"‚úÖ File verification passed ({file_size:.1f} KB)")
    else:
        safe_print(f"‚ùå Output file does not exist")
    
    safe_print("=" * 60)
    
    # Clean up progress file
    if os.path.exists(progress_file):
        try:
            os.remove(progress_file)
            safe_print(f"üóëÔ∏è  Cleaned checkpoint file")
        except:
            pass


# ==================== Entry Point ====================
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Multi-threaded video comparison judgment")
    parser.add_argument("--prompt", required=True, help="Path to prompt template file")
    parser.add_argument("--structured", required=True, help="Path to structured checklist JSON")
    parser.add_argument("--response", required=True, help="Path to model response JSON")
    parser.add_argument("--output", required=True, help="Path to output JSON")
    parser.add_argument("--api-url", required=True, help="API endpoint URL")
    parser.add_argument("--api-key", required=True, help="API key")
    parser.add_argument("--model", default=MODEL_NAME, help="Model name")
    parser.add_argument("--threads", type=int, default=4, help="Number of threads")
    parser.add_argument("--concurrent", type=int, default=15, help="Max concurrent requests")
    
    args = parser.parse_args()
    
    try:
        # Load prompt template
        prompt_template = load_prompt_template(args.prompt)
        
        judge_checklist_multithreaded(
            prompt_template,
            args.structured,
            args.response,
            args.output,
            args.api_url,
            args.api_key,
            args.model,
            args.threads,
            args.concurrent
        )
    except KeyboardInterrupt:
        safe_print("\n‚ö†Ô∏è  User interrupted")
    except Exception as e:
        safe_print(f"\n‚ùå Exception exit: {e}")
        traceback.print_exc()
